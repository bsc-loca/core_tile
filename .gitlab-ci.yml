include:
  - project: 'hwdesign/ci/generic_ci'
    ref: $GENERIC_CI_BRANCH
    file:
      - jobs_template.yml
      - badges.yml

## This workflow avoids duplicate pipelines when there is an open merge request (commit_branch + merge_request) 
## so only the open merge request will be executed and not the commit_branch. PIPELINE_BRANCH will be used to refer to
## CI_COMMIT_BRANCH or CI_MERGE_REQUEST_SOURCE_BRANCH_NAME, we will not differentiate between them.
## If a rule matches, when: always is the default, and when: never is the default if nothing matches
workflow:
  rules:
    - !reference [.rules, global_std]

.rules_default:
    - if: (($CI_PIPELINE_SOURCE == 'web' || $CI_PIPELINE_SOURCE == 'schedule') && $do_gen_bitstream_pkg)
      when: never
    - if: ($do_synthesis && ($CI_PIPELINE_SOURCE == "schedule" || $CI_PIPELINE_SOURCE == "web"))
      when: never
    - if: (($CI_PIPELINE_SOURCE == 'web' || $CI_PIPELINE_SOURCE == 'schedule') && $OPERATION == "boot")
      when: never
    - if: '$CI_PIPELINE_SOURCE == "pipeline"'
      when: never
    - if: (($CI_PIPELINE_SOURCE == "schedule" || 
          $CI_PIPELINE_SOURCE == "web" || 
          $CI_PIPELINE_SOURCE == "pipeline") && $REGRESS_TYPE)
      when: never
    - when: always

.rules_merge_request:
    - !reference [.rules, only_merge]

.rules_uvm_smoke:
    - if: '$CI_PIPELINE_SOURCE == "pipeline"'
      when: always
    - if: '$do_test_uvm || $CI_COMMIT_MESSAGE =~ /#do_test_uvm/'
      when: always
    - !reference [.rules_uvm_scheduled]
    - !reference [.rules_merge_request]

.rules_uvm_scheduled:
  - if: (($CI_PIPELINE_SOURCE == "schedule" || 
          $CI_PIPELINE_SOURCE == "web" || 
          $CI_PIPELINE_SOURCE == "pipeline") && $REGRESS_TYPE &&
         ($testname == null || 
          $testname == "base_rvv" && $TESTS_NAMES =~ "/\[base_rvv\]/"))
    when: always
    variables:
      N_TESTS: $GENERATED_TESTS_RVV
  - if: (($CI_PIPELINE_SOURCE == "schedule" || 
          $CI_PIPELINE_SOURCE == "web" || 
          $CI_PIPELINE_SOURCE == "pipeline") && $REGRESS_TYPE &&
         ($testname == null || 
          $testname == "base_scalar" && $TESTS_NAMES =~ "/\[base_scalar\]/" ||
          $testname == "riscv_total_random_test" && $TESTS_NAMES =~ "/\[riscv_total_random_test\]/"))
    when: always
    variables:
      N_TESTS: $GENERATED_TESTS_SCALAR

.rules_synthesis:
  - if: ($do_synthesis && ($CI_PIPELINE_SOURCE == "schedule" || $CI_PIPELINE_SOURCE == "web"))

.rules_fpga:
    - if:  $CI_PIPELINE_SOURCE == "pipeline"
      when: never
    - if: ($CI_COMMIT_TAG || 
          ($CI_PIPELINE_SOURCE == 'web' || $CI_PIPELINE_SOURCE == 'schedule') && $do_gen_bitstream_pkg)
      variables:
        GEN_BITSTREAM_PKG: "true"
    - if: (($CI_PIPELINE_SOURCE == 'web' || $CI_PIPELINE_SOURCE == 'schedule') && $OPERATION == "boot")

stages:
  - linting
  - building
  - simulation
  - synthesis
  - fpga
  - coverage
  - upload

lint-verilator:
  extends: .verilator
  stage: linting
  rules:
    - !reference [.rules_default]
  script:
    - verilator --version
    - make lint-verilator
  allow_failure: true

lint-spyglass:
  extends: .spyglass
  stage: linting
  rules:
    - !reference [.rules_default]
  variables:
    # Needed for proper exit code detection 
    # https://gitlab.com/gitlab-org/gitlab-runner/-/issues/28658
    FF_USE_NEW_BASH_EVAL_STRATEGY: 1 
  script:
    - ./scripts/lint_spyglass.sh
  allow_failure:
    exit_codes: 11 # Only allow failure in case there are warnings but no errors

lint-dc-elab:
  extends: .dc_shell
  stage: linting
  rules:
    - if: ($CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TARGET_BRANCH_NAME != "main") # If not merging to main, skip this
      when: never
    - !reference [.rules_merge_request]
  timeout: 1 hrs
  variables:
    RUNNER_SCRIPT_TIMEOUT: 50m
    LOG_DC_SHELL: dc_elab.$CI_PIPELINE_ID.log 
  script:
    - make dc_elab > ${LOG_DC_SHELL}
    - !reference [.scripts, dc_elab_check_errors]
  artifacts:
    paths:
        - ${LOG_DC_SHELL}

lint-vc-static:
  extends: .vc_static  
  stage: linting
  rules:
    !reference [.rules_merge_request]
  variables:
    LOG_VC_STATIC: vc_static.$CI_PIPELINE_ID.log
  script:
    - make lint-vc 2>&1 | tee ${LOG_VC_STATIC}
    - !reference [.scripts, vc_static_check_errors]
  artifacts:
    paths:
        - report_lint.txt

build-isa-tests:
  extends: .questa_riscv
  stage: building
  rules:
    - !reference [.rules_default]
  script:
    - $RISCV_GCC --version
    - make build-isa-tests
  artifacts:
    paths:
    - tb/tb_isa_tests/build

build-benchmarks:
  extends: .questa_riscv  
  stage: building
  rules:
    - !reference [.rules_default]
  script:
    - $RISCV_GCC --version
    - make build-benchmarks BENCHMARKS_CI=1
  artifacts:
    paths:
    - benchmarks

build-simulator:
  extends: .questa_riscv  
  stage: building
  rules:
    - !reference [.rules_default]
  script:
    - module load verilator
    - module load gcc
    - verilator --version
    - gcc --version
    - make sim
  artifacts:
    paths:
    - simulator/reference/build/libdisasm.so
    - sim
    - bootrom.hex

build-uvm:
  extends: .questa_riscv
  stage: building
  rules:
    - !reference [.rules_uvm_scheduled]
    - !reference [.rules_uvm_smoke]
  variables:
    CORE_TYPE: sargantana
    SPIKE_URL_BASE: https://gitlab.bsc.es/api/v4/projects/1982/packages/generic/master_bsc/0.0.1/spike
  script:
    - make clone_dv
    - make clone_ci_scripts
    - cd verif/core_uvm
    - make clone_selected_tests
    - module load verilator
    - verilator --version
    - module load gcc
    - gcc --version
    - make compile_all SARGANTANA=enable RTLDIR=../../ ${COVERAGE_ARG} INTERRUPTS=enable
  artifacts:
    untracked: true
    paths:
      - verif/core_uvm

build-vcs:
  extends: .vcs_riscv
  stage: building
  rules:
    - !reference [.rules_default]
  timeout: 1 hrs
  script:
    - make libdisasm
    - export CI_VCS=1
    - ./simulator/vcs/sim.sh
  artifacts:
    paths:
    - simulator/reference/build/libdisasm.so
    - build_vcs

# Only needed by 'torture'
#build-spike:
#  stage: building
#  rules:
#    - if: ($CI_PIPELINE_SOURCE == "schedule")
#      when: always
#  script:
#    - gcc --version
#    - make spike
#  artifacts:
#    paths:
#    - simulator/reference/build/spike
#    expire_in: 1 week

#build-torture:
#  stage: building
#  rules:
#    - if: ($CI_PIPELINE_SOURCE == "schedule")
#      when: always
#  script:
#    - $RISCV_GCC --version
#    - make build-torture
#  artifacts:
#    paths:
#    - tb/tb_torture/riscv-torture/output

isa-tests:
  extends: .questa_riscv
  stage: simulation
  rules:
    - !reference [.rules_default]
  dependencies:
    - build-simulator
    - build-isa-tests
  script:
    - ./tb/tb_isa_tests/run-tests.py ./sim tb/tb_isa_tests/build/isa

benchmarks:
  extends: .questa_riscv  
  stage: simulation
  rules:
    - !reference [.rules_default]
  dependencies:
    - build-simulator
    - build-benchmarks
  timeout: 4h
  variables:
    RUNNER_SCRIPT_TIMEOUT: 3h50m
  script:
    - ./run-benchmarks.sh

vcs:
  extends: .vcs_riscv
  stage: simulation
  rules:
    - !reference [.rules_default]
  timeout: 1 hrs
  dependencies:
    - build-vcs
    - build-isa-tests
    - build-simulator
  script:
    - cp bootrom.hex build_vcs/bootrom.hex
    - ./build_vcs/simv +vcs+lic+wait +load=./tb/tb_isa_tests/build/isa/rv64ui-p-add

# Has many problemes, never managed to get it working properly...
#torture:
#  stage: simulation
#  rules:
#    - if: ($CI_PIPELINE_SOURCE == "schedule")
#      when: always
#  dependencies:
#    - build-simulator
#    - build-torture
#    - build-spike
#  timeout: 4h
#  parallel:
#    matrix:
#      - CONFIG:
#        - peta
#        - large_fp
#        - tlb_large
#        - tlb_medium
#  script:
#    - tb/tb_torture/run_torture.sh $CONFIG
#  artifacts:
#    when: on_failure
#    paths:
#    - tb/tb_torture/signatures

.riscv_dv_generate: &riscv_dv_generate
  - echo $BASE_TESTS
  - echo $N_ITERATIONS
  - echo $N_TESTS
  - echo $core
  - source ci_scripts/generate_tests.sh $N_ITERATIONS "python3 -u ./riscv-dv/run.py -tn $testname -ct ./riscv-dv/BSC-targets/sargantana --isa rv64gv --mabi lp64d --gen_timeout 18000 -si questa -o ./generated_tests -i $N_TESTS -s gen,gcc_compile"
   

uvm-random-regression:
  extends: .questa_riscv
  stage: simulation
  parallel:
    matrix:
      - testname: [riscv_total_random_test, base_scalar, base_rvv]
  rules:
    - !reference [ .rules_uvm_scheduled ]
  timeout: 8h
  variables:
    RUNNER_SCRIPT_TIMEOUT: 7h30m
    BADGE_GEN: "true"    
    CORE_TYPE: sargantana
  script:
    - cd verif/core_uvm
    - *riscv_dv_generate
    - python3 -u run.py -r riscv-dv_regression.yaml ${COVERAGE} --interrupts ${TIMEOUT_RANDOM} || result=$(echo $?)
    - mv ./regress/results/sargantana_random_riscvdv_tests ./regress/results/sargantana_random_riscvdv_${testname}
    - if [ ! -z $result ];then exit ${result}; fi
  artifacts:
    untracked: true
    paths:
        - verif/core_uvm/sim/build/comp_transcript
        - verif/core_uvm/regress/results/sargantana_random_riscvdv_${testname}/*
        - verif/core_uvm/generated_tests_*/*
        - verif/core_uvm/tests/build/generated_tests/*
                                                   
uvm-regression:
  extends: .questa_riscv
  stage: simulation
  parallel:
    matrix:
      - regression_type: [isa_tests, rvv_tests, selected_tests]
  rules:
    - !reference [.rules_uvm_smoke]
  variables:
    CORE_TYPE: sargantana
    BADGE_GEN: "true"
  script:
    - cd verif/core_uvm
    - python3 -u run.py -r ${regression_type}_sargantana.yaml ${COVERAGE} ${IGNORE_EXCLUSION} ${TIMEOUT_REGRESSION}
  artifacts:
    untracked: true
    paths:
        - verif/core_uvm/sim/build/comp_transcript
        - verif/core_uvm/regress/results

dc-synthesis:
  extends: .dc_shell
  stage: synthesis
  rules:
    - !reference [.rules_synthesis]
  variables:
    SARGANTANA_OUT_DIR: /nfs/synthesis/CI-SARGANTANA
  script:
    - make dc_syn 2>&1 | tee ./dc_syn.$CI_PIPELINE_ID.log 
    - mkdir -p $SARGANTANA_OUT_DIR/$CI_COMMIT_REF_NAME/$CI_COMMIT_SHORT_SHA
    - find $SARGANTANA_OUT_DIR/$CI_COMMIT_REF_NAME -mindepth 1 -mtime +30 -delete
    - cp ./dc_syn.$CI_PIPELINE_ID.log $SARGANTANA_OUT_DIR/$CI_COMMIT_REF_NAME/$CI_COMMIT_SHORT_SHA
    - cp -r build/dc/* $SARGANTANA_OUT_DIR/$CI_COMMIT_REF_NAME/$CI_COMMIT_SHORT_SHA
    - ln -srfn $SARGANTANA_OUT_DIR/$CI_COMMIT_REF_NAME/$CI_COMMIT_SHORT_SHA $SARGANTANA_OUT_DIR/$CI_COMMIT_REF_NAME/latest    
  artifacts:
    paths:
      - dc_syn.$CI_PIPELINE_ID.log

#fpga-prepare:
#  extends: .basic_no_clone
#  stage: fpga
#  rules:
#    - !reference [.rules_merge_request]
#    - !reference [.rules_fpga]
#  needs: []
#  artifacts:
#    reports:
#      dotenv: vars.env
#  script:
#    - echo boot_bsc_linux_url=$BOOT_BSC_LINUX_URL > vars.env
#    - cat vars.env

fpga:
  stage: fpga
  rules:
    - !reference [.rules_merge_request]
    - !reference [.rules_fpga]
  #needs: [fpga-prepare]
  needs: []
  variables:
    COMMIT_SHA: $CI_COMMIT_SHA
    COMMIT_REF: $CI_COMMIT_REF_NAME
    BSC_LINUX_URL: $boot_bsc_linux_url
    #GEN_BITSTREAM_PKG: defined in  rules_fpga
  trigger:
    project: hwdesign/fpga/integration-lab/fpga-shell
    branch: ${BRANCH_FPGA_SHELL}
    strategy: depend

publish_badges:
  extends: .publish_badges
  stage: upload
  rules:
    - !reference [.rules_uvm_scheduled]
    - !reference [.rules_uvm_smoke]

coverage-report:
  extends: .coverage-report
  stage: coverage
  variables:
    ARGS_OVERALL_COVERAGE: -f ./verif/core_uvm/regress/results/html_report/files/z1.js -d /top_tb/ka_th
    CI_SCRIPTS_PATH: verif/core_uvm/ci_scripts
    RESULTS_PATH: verif/core_uvm/regress/results
    PUBLISH_PATH: /nfs/verification/sargantana-dv
  rules:
    - !reference [.rules_uvm_scheduled]
    - !reference [.rules_uvm_smoke]
